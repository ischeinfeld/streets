{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "#from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dim replaced by 1\n",
    "output_dim = 2\n",
    "class GNNStackClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "            x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "    def loss(self, pred, actual):\n",
    "        #print(pred.numpy())\n",
    "        #print(actual.numpy())\n",
    "        #print('\\n\\n\\n')\n",
    "        return F.nll_loss(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dim replaced by 1\n",
    "output_dim = 1\n",
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GNNStack, self).__init__()\n",
    "        #self.convs = nn.ModuleList()\n",
    "        #self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        #self.convs.append(nn.Linear(input_dim, hidden_dim))\n",
    "        for l in range(0):\n",
    "            #self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "            self.convs.append(nn.Linear( hidden_dim, hidden_dim))\n",
    "        # post-message-passing\n",
    "        #self.post_mp = nn.Sequential(\n",
    "        #    nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
    "        #    nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        \n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), nn.Dropout(0.25), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 0\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        #print(x)\n",
    "        #if data.num_node_features == 0:\n",
    "        #    x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            #x = self.convs[i](x, edge_index)\n",
    "            x = self.convs[i](x)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, actual):\n",
    "        #print(pred.detach().numpy())\n",
    "        #print(actual.detach().numpy())\n",
    "        #print('\\n\\n\\n')\n",
    "        return F.mse_loss(pred, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'experiments/line_graphs/new_york.graphml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b1a1dc934f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graphml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiments/line_graphs/new_york.graphml'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/pablosantos/Documents/CS224WProject/streets/env/lib/python3.7/site-packages/decorator.py:decorator-gen-785>\u001b[0m in \u001b[0;36mread_graphml\u001b[0;34m(path, node_type, edge_key_type)\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS224WProject/streets/env/lib/python3.7/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mclose_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'experiments/line_graphs/new_york.graphml'"
     ]
    }
   ],
   "source": [
    "LG = nx.read_graphml('experiments/line_graphs/new_york.graphml',node_type=int)\n",
    "print(LG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11506, {'oneway': False, 'length': 42.948, 'speed_mph_mean': 13.936, 'speed_mph_stddev': 3.7220000000000004, 'speed_mph_p50': 13.69, 'speed_mph_p85': 16.535750000000004})\n",
      "(11506, {'oneway': False, 'length': 42.948, 'speed_mph_mean': 13.936, 'speed_mph_stddev': 3.7220000000000004, 'speed_mph_p50': 13.69, 'speed_mph_p85': 16.535750000000004, 'y': [16.535750000000004], 'x': [16.535750000000004], 'train_mask': True, 'test_mask': False})\n",
      "\n",
      "\n",
      "(11506, {'oneway': False, 'length': 42.948, 'speed_mph_mean': 13.936, 'speed_mph_stddev': 3.7220000000000004, 'speed_mph_p50': 13.69, 'speed_mph_p85': 16.535750000000004, 'y': [16.535750000000004], 'x': [16.535750000000004], 'train_mask': True, 'test_mask': False})\n",
      "\n",
      "\n",
      "(11506, 4845, {})\n"
     ]
    }
   ],
   "source": [
    "#LG = nx.read_graphml('experiments/preprocessed/san_francisco.graphml',node_type=int)\n",
    "pickle_in = open('./experiments/line_graphs/SF_LG'+\".pkl\", \"rb\")\n",
    "LG = pickle.load(pickle_in)\n",
    "#LG = nx.read_graphml('experiments/line_graphs/new_york.graphml',node_type=int)\n",
    "#['speed_mph_p50','speed_mph_p85', 'speed_mph_stddev','speed_mph_mean', 'length', 'oneway']\n",
    "target = 'speed_mph_p85'\n",
    "node_feature_list = [target]\n",
    "edge_feature_list = ['x','y']\n",
    "\n",
    "for n in LG.nodes(data=True):\n",
    "    print(n)\n",
    "    break\n",
    "lg_node_attr = {}\n",
    "node_relabel = {}\n",
    "\n",
    "IDs = {}\n",
    "cur_ID = 0\n",
    "\n",
    "#To make torch_geometric.data extraction easier, remove every node that doesn't have ALL of the features in node_feature_list\n",
    "remove = []\n",
    "#num_train = 24580*0.8\n",
    "num_train = 15065*0.8\n",
    "cur_num_train = 0\n",
    "#seperate into train and test\n",
    "for key,_ in LG.nodes(data=True):\n",
    "    new_edge_data = copy.deepcopy(LG.nodes()[key])\n",
    "    skip = False\n",
    "    for k in list(new_edge_data.keys()):\n",
    "        if k not in node_feature_list:\n",
    "            del new_edge_data[k]\n",
    "    for k in node_feature_list:\n",
    "        if k not in new_edge_data:\n",
    "            skip = True\n",
    "            break\n",
    "    if skip == True:\n",
    "        remove.append(key)\n",
    "        continue\n",
    "    x = []\n",
    "    edge_x_y = {}\n",
    "    for k,v in new_edge_data.items():\n",
    "        if k == target:\n",
    "            edge_x_y['y'] = [float(v)]\n",
    "        #    continue\n",
    "        x.append(float(v))\n",
    "    if skip == True:\n",
    "        remove.append(key)\n",
    "        continue\n",
    "    edge_x_y['x'] = x\n",
    "    if cur_num_train > num_train:\n",
    "        edge_x_y['train_mask'] = False\n",
    "        edge_x_y['test_mask'] = True\n",
    "    else:\n",
    "        edge_x_y['train_mask'] = True\n",
    "        edge_x_y['test_mask'] = False \n",
    "    lg_node_attr[key] = edge_x_y\n",
    "    cur_num_train+=1   \n",
    "    \n",
    "for i in remove:\n",
    "    LG.remove_node(i)\n",
    "    \n",
    "#nx.relabel.relabel_nodes(LG,node_relabel,False)\n",
    "nx.set_node_attributes(LG,lg_node_attr)\n",
    "\n",
    "for n in LG.nodes(data=True):\n",
    "    print(n)\n",
    "    break\n",
    "print('\\n')\n",
    "\n",
    "#append in and out degrees. This had to be done seperately since we want to do it after we remove nodes\n",
    "#for key,_ in LG.nodes(data=True):\n",
    "#    new_edge_data = LG.nodes()[key]\n",
    "#    new_edge_data['x'].append(LG.out_degree(key))\n",
    "#    new_edge_data['x'].append(LG.in_degree(key))\n",
    "\n",
    "#nx.set_node_attributes(LG,{})\n",
    "#nx.set_edge_attributes(LG,{})\n",
    "for n in LG.nodes(data=True):\n",
    "    print(n)\n",
    "    break\n",
    "        \n",
    "print('\\n')\n",
    "for e in LG.edges(data=True):\n",
    "    print(e)\n",
    "    break\n",
    "\n",
    "#nx.write_graphml(LG,'experiments/preprocessed/' + CITY_NAME + \".graphml\")\n",
    "#'./experiments/pyData/SF_LG_x_all_y_p85'+\".pkl\"\n",
    "pyData = from_networkx(LG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[420.]\n",
      " [420.]\n",
      " [420.]\n",
      " ...\n",
      " [420.]\n",
      " [420.]\n",
      " [420.]]\n",
      "[Data(edge_index=[2, 60626], test_mask=[20580], train_mask=[20580], x=[20580, 1], y=[20580, 1])]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open('./experiments/pyData/SF_LG_x_all_y_p85'+\".pkl\", \"rb\")\n",
    "pyData = pickle.load(pickle_in)\n",
    "print(pyData.y.detach().numpy())\n",
    "loader = DataLoader([pyData], batch_size=1)\n",
    "print(loader.dataset)\n",
    "print(len(loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation=False):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = data.y[mask]\n",
    "        #print(label, pred)\n",
    "        correct += pred.eq(label).sum().item()\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.test_mask).item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 160371.7656. Test accuracy: 0.0000\n",
      "Epoch 10. Loss: 60194.5430. Test accuracy: 0.0000\n",
      "Epoch 20. Loss: 43241.1016. Test accuracy: 0.0000\n",
      "Epoch 30. Loss: 44869.9766. Test accuracy: 0.0000\n",
      "Epoch 40. Loss: 43061.9844. Test accuracy: 0.0000\n",
      "Epoch 50. Loss: 42370.5664. Test accuracy: 0.0000\n",
      "Epoch 60. Loss: 40873.2266. Test accuracy: 0.0000\n",
      "Epoch 70. Loss: 41061.6250. Test accuracy: 0.0000\n",
      "Epoch 80. Loss: 40610.0078. Test accuracy: 0.0000\n",
      "Epoch 90. Loss: 40670.9219. Test accuracy: 0.0000\n",
      "Epoch 100. Loss: 39331.1836. Test accuracy: 0.0000\n",
      "Epoch 110. Loss: 39942.2773. Test accuracy: 0.0000\n",
      "Epoch 120. Loss: 38353.7695. Test accuracy: 0.0000\n",
      "Epoch 130. Loss: 38764.0234. Test accuracy: 0.0000\n",
      "Epoch 140. Loss: 38094.4258. Test accuracy: 0.0000\n",
      "Epoch 150. Loss: 37781.1562. Test accuracy: 0.0000\n",
      "Epoch 160. Loss: 37394.8750. Test accuracy: 0.0000\n",
      "Epoch 170. Loss: 37179.6016. Test accuracy: 0.0000\n",
      "Epoch 180. Loss: 36268.2422. Test accuracy: 0.0000\n",
      "Epoch 190. Loss: 35774.9375. Test accuracy: 0.0000\n",
      "Epoch 200. Loss: 36372.4297. Test accuracy: 0.0000\n",
      "Epoch 210. Loss: 35427.6953. Test accuracy: 0.0000\n",
      "Epoch 220. Loss: 34063.3359. Test accuracy: 0.0000\n",
      "Epoch 230. Loss: 34048.6836. Test accuracy: 0.0000\n",
      "Epoch 240. Loss: 34045.3516. Test accuracy: 0.0000\n",
      "Epoch 250. Loss: 33788.9531. Test accuracy: 0.0000\n",
      "Epoch 260. Loss: 33093.6680. Test accuracy: 0.0000\n",
      "Epoch 270. Loss: 33199.8008. Test accuracy: 0.0000\n",
      "Epoch 280. Loss: 33066.9180. Test accuracy: 0.0000\n",
      "Epoch 290. Loss: 32407.1895. Test accuracy: 0.0000\n",
      "Epoch 300. Loss: 31479.6406. Test accuracy: 0.0000\n",
      "Epoch 310. Loss: 31139.6113. Test accuracy: 0.0000\n",
      "Epoch 320. Loss: 30809.3477. Test accuracy: 0.0000\n",
      "Epoch 330. Loss: 30296.8711. Test accuracy: 0.0000\n",
      "Epoch 340. Loss: 30274.3340. Test accuracy: 0.0000\n",
      "Epoch 350. Loss: 29419.9531. Test accuracy: 0.0000\n",
      "Epoch 360. Loss: 29466.9551. Test accuracy: 0.0000\n",
      "Epoch 370. Loss: 28984.2402. Test accuracy: 0.0000\n",
      "Epoch 380. Loss: 29072.0820. Test accuracy: 0.0000\n",
      "Epoch 390. Loss: 28657.0938. Test accuracy: 0.0000\n",
      "Epoch 400. Loss: 27687.8516. Test accuracy: 0.0000\n",
      "Epoch 410. Loss: 27146.3301. Test accuracy: 0.0000\n",
      "Epoch 420. Loss: 27499.8848. Test accuracy: 0.0000\n",
      "Epoch 430. Loss: 26773.2559. Test accuracy: 0.0000\n",
      "Epoch 440. Loss: 26603.9785. Test accuracy: 0.0000\n",
      "Epoch 450. Loss: 26018.1055. Test accuracy: 0.0000\n",
      "Epoch 460. Loss: 25585.4453. Test accuracy: 0.0000\n",
      "Epoch 470. Loss: 26199.0176. Test accuracy: 0.0000\n",
      "Epoch 480. Loss: 24726.4062. Test accuracy: 0.0000\n",
      "Epoch 490. Loss: 24345.8848. Test accuracy: 0.0000\n",
      "Epoch 500. Loss: 24167.9805. Test accuracy: 0.0000\n",
      "Epoch 510. Loss: 24247.2227. Test accuracy: 0.0000\n",
      "Epoch 520. Loss: 23905.5996. Test accuracy: 0.0000\n",
      "Epoch 530. Loss: 23430.5527. Test accuracy: 0.0000\n",
      "Epoch 540. Loss: 23105.1211. Test accuracy: 0.0000\n",
      "Epoch 550. Loss: 22889.0820. Test accuracy: 0.0000\n",
      "Epoch 560. Loss: 22562.2949. Test accuracy: 0.0000\n",
      "Epoch 570. Loss: 22570.5840. Test accuracy: 0.0000\n",
      "Epoch 580. Loss: 21331.7227. Test accuracy: 0.0000\n",
      "Epoch 590. Loss: 21847.7520. Test accuracy: 0.0000\n",
      "Epoch 600. Loss: 21740.5020. Test accuracy: 0.0000\n",
      "Epoch 610. Loss: 21178.4902. Test accuracy: 0.0000\n",
      "Epoch 620. Loss: 20473.4746. Test accuracy: 0.0000\n",
      "Epoch 630. Loss: 20047.8379. Test accuracy: 0.0000\n",
      "Epoch 640. Loss: 19635.2656. Test accuracy: 0.0000\n",
      "Epoch 650. Loss: 19928.0059. Test accuracy: 0.0000\n",
      "Epoch 660. Loss: 19761.7988. Test accuracy: 0.0000\n",
      "Epoch 670. Loss: 19580.4023. Test accuracy: 0.0000\n",
      "Epoch 680. Loss: 19761.1777. Test accuracy: 0.0000\n",
      "Epoch 690. Loss: 18977.8711. Test accuracy: 0.0000\n",
      "Epoch 700. Loss: 17987.4746. Test accuracy: 0.0000\n",
      "Epoch 710. Loss: 18076.8574. Test accuracy: 0.0000\n",
      "Epoch 720. Loss: 18131.8398. Test accuracy: 0.0000\n",
      "Epoch 730. Loss: 18404.6582. Test accuracy: 0.0000\n",
      "Epoch 740. Loss: 17960.6328. Test accuracy: 0.0000\n",
      "Epoch 750. Loss: 17281.7012. Test accuracy: 0.0000\n",
      "Epoch 760. Loss: 16771.0566. Test accuracy: 0.0000\n",
      "Epoch 770. Loss: 16695.5332. Test accuracy: 0.0000\n",
      "Epoch 780. Loss: 16501.5430. Test accuracy: 0.0000\n",
      "Epoch 790. Loss: 16296.7783. Test accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    test_loader = loader = DataLoader([pyData], batch_size=1)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(max(pyData.num_node_features, 1), 32)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.25)\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(800):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        #writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "            #writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "    for data in test_loader:\n",
    "        pred = model(data).detach().numpy()\n",
    "        label = data.y.detach().numpy()\n",
    "        #plt.plot(range(len(label)),label)\n",
    "        #plt.plot(range(len(label)),pred)\n",
    "        plt.scatter(label,pred)\n",
    "        plt.ylabel('pred')\n",
    "        plt.xlabel('label')\n",
    "        plt.title('label vs pred')\n",
    "        plt.show()\n",
    "        break\n",
    "    #return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for data in test_loader:\n",
    "        pred = model(data).detach().numpy()\n",
    "        label = data.y.detach().numpy()\n",
    "        plt.plot(range(len(label)),label)\n",
    "        plt.plot(range(len(pred)),pred)\n",
    "        #plt.scatter(label,pred)\n",
    "        plt.ylabel('pred')\n",
    "        plt.xlabel('label')\n",
    "        plt.title('label vs pred')\n",
    "        plt.show()\n",
    "        #print(pred)\n",
    "        #for i in range(len(pred)):\n",
    "        #    print(label[i],pred[i])\n",
    "        #print(label)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[420.]\n",
      " [420.]\n",
      " [420.]\n",
      " ...\n",
      " [420.]\n",
      " [420.]\n",
      " [420.]]\n"
     ]
    }
   ],
   "source": [
    "for d in test_loader:\n",
    "    print(d.y.detach().numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
